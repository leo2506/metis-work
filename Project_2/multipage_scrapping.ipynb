{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:31:30.797375Z",
     "start_time": "2018-10-07T23:31:29.300841Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "\n",
    "chromedriver = f\"{os.environ['HOME']}/.local/bin/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "driver = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:37.517344Z",
     "start_time": "2018-10-07T23:54:32.447022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For test purposes\n",
    "url = \"https://www.realtor.com/realestateandhomes-detail/4745-16th-Ave-NE_Seattle_WA_98105_M14191-38985https://www.realtor.com/realestateandhomes-detail/4745-16th-Ave-NE_Seattle_WA_98105_M14191-38985\"\n",
    "driver.get(url)\n",
    "soup1 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "type(soup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:37.524976Z",
     "start_time": "2018-10-07T23:54:37.519508Z"
    }
   },
   "outputs": [],
   "source": [
    "def floorplan_scrapper(soup, room_type):\n",
    "    content = soup.find(id=room_type)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['Room Type','Bath','Sqft','Price'])\n",
    "    \n",
    "    for row in content.find_all('tr'):\n",
    "        name = room_type.replace('floorplan-','')\n",
    "        bath = float(row.find(class_=\"col-bath\").text.strip()[0])\n",
    "        sqft = float(row.\n",
    "                     find(class_=\"col-sqft\").\n",
    "                     text.strip().\n",
    "                     split()[0].\n",
    "                     replace(',',''))\n",
    "        price = row.find(class_=\"col-price\").text.strip()\n",
    "        if price == \"N/A\":\n",
    "            continue\n",
    "        price = float(price.replace('$','').replace(',',''))\n",
    "        \n",
    "        temp = [name,bath,sqft,price]\n",
    "        df = df.append(pd.DataFrame([temp],columns=['Room Type','Bath','Sqft','Price']),ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:37.532422Z",
     "start_time": "2018-10-07T23:54:37.527137Z"
    }
   },
   "outputs": [],
   "source": [
    "def floorplan_scrapper1(soup):\n",
    "    ids = []\n",
    "    floorplan=soup.find(class_=\"list-floorplans\")\n",
    "    df = pd.DataFrame(columns=['Room Type','Bath','Sqft','Price'])\n",
    "    if floorplan: \n",
    "        for panel in floorplan.find_all(class_=\"panel\"):\n",
    "            ids.append(panel[\"id\"])\n",
    "\n",
    "        for id_ in ids:\n",
    "            df = df.append(floorplan_scrapper(soup, id_),ignore_index=True)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:37.569475Z",
     "start_time": "2018-10-07T23:54:37.534776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Room Type</th>\n",
       "      <th>Bath</th>\n",
       "      <th>Sqft</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-bedroom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2495.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Room Type  Bath    Sqft   Price\n",
       "0  3-bedroom   2.0  1200.0  2495.0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test purposes\n",
    "df_floorplan = floorplan_scrapper1(soup1)\n",
    "df_floorplan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:37.596403Z",
     "start_time": "2018-10-07T23:54:37.576946Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_address_str(address):\n",
    "    a = address.text.strip().split('\\n')[1:]\n",
    "    b = []\n",
    "    for add in a:\n",
    "        b.append(add.strip())\n",
    "    return ' '.join(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:39.118942Z",
     "start_time": "2018-10-07T23:54:39.112533Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_features_list(list_a):    \n",
    "    la = []\n",
    "    for l in list_a:\n",
    "        la.append(l.text.strip().split('\\n'))\n",
    "    lb = []\n",
    "    for l in la:\n",
    "        lbb = []\n",
    "        for ll in l:\n",
    "            lbb.append(ll.strip())\n",
    "        lb.append(lbb)\n",
    "    return lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:40.597739Z",
     "start_time": "2018-10-07T23:54:40.585536Z"
    }
   },
   "outputs": [],
   "source": [
    "def trait_scrapper(soup):\n",
    "    ty = soup.find(\"li\", attrs={\"data-label\":\"property-type\"})\n",
    "    bu = soup.find(\"li\", attrs={\"data-label\":\"property-year\"})\n",
    "        \n",
    "    # Add columns of property type and year-built\n",
    "    df = pd.DataFrame(columns=[\"Type\", \"Built\"])\n",
    "    if ty is not None:\n",
    "        df[\"Type\"] = (ty.\n",
    "                      find(text=re.compile(\"Type\")).\n",
    "                      find_next(\"div\").\n",
    "                      contents) \n",
    "    if bu is not None:\n",
    "        df[\"Built\"] = (bu.\n",
    "                       find(text=re.compile(\"Built\")).\n",
    "                       find_next(\"div\").\n",
    "                       contents)\n",
    "    \n",
    "    # Add columns of property name and address\n",
    "    if soup.find(class_=\"ldp-header-address \"):\n",
    "        address = soup.find(class_=\"ldp-header-address \").find(itemprop=\"address\")\n",
    "        name = address.text.strip().split('\\n')[0]\n",
    "        if name[0].isnumeric():\n",
    "            df[\"Address\"] = name + ' ' + get_address_str(address)\n",
    "        else:    \n",
    "            df[\"Address\"] = get_address_str(address)\n",
    "            df[\"Name\"] = name\n",
    "\n",
    "    # Add columns of Community Features and Unit Features,\n",
    "    # which are stored in a list\n",
    "    section = soup.find(class_=\"listing-subsection-features\")\n",
    "    if section:\n",
    "        list1 = get_features_list(section.find_all(class_=\"col-sm-6\"))\n",
    "    \n",
    "    # Change df into object type to enable it to store list values\n",
    "    df.astype(object)\n",
    "    if soup.find(text=re.compile(\"Community Features\")):\n",
    "        df[\"Community Features\"] = [list1[0]+list1[1]]\n",
    "        if soup.find(text=re.compile(\"Unit Features\")):       \n",
    "            df[\"Unit Features\"] = [list1[2]+list1[3]]\n",
    "    elif soup.find(text=re.compile(\"Unit Features\")):\n",
    "        df[\"Unit Features\"] = [list1[0]+list1[1]]\n",
    "    \n",
    "    # Add columns of number of surrounding rated schools\n",
    "    # and their average ratings \n",
    "    school = soup.find_all(class_=\"school-rating\")\n",
    "    \n",
    "    rating_list = []\n",
    "    for s in school:\n",
    "        rating_list.append(s.text)\n",
    "    \n",
    "    rating = [int(a) for a in rating_list if a.isnumeric() ]\n",
    "    df[\"Number of Schools\"] = len(rating)\n",
    "    df[\"Average School Rating\"] = round(np.mean(rating),2)\n",
    "    \n",
    "    # Add columns of median rental price and median listing price\n",
    "    # in the neighborhood\n",
    "    nb = soup.find_all(class_ = \"neighborhood-flex-item\")\n",
    "    \n",
    "    if len(nb) != 0:\n",
    "        nb_list = []\n",
    "        for nb1 in nb:\n",
    "            nb_list.append(nb1.text.strip().split('\\n'))\n",
    "\n",
    "        title1 = nb_list[0][-1].strip()\n",
    "        title2 = nb_list[1][-1].strip()\n",
    "        value1 = float(nb_list[0][0].replace('$','').replace(',',''))\n",
    "        value2 = float(nb_list[1][0].replace('$','').replace(',',''))\n",
    "        df[title1] = value1\n",
    "        df[title2] = value2\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:41.532508Z",
     "start_time": "2018-10-07T23:54:41.495904Z"
    }
   },
   "outputs": [],
   "source": [
    "soup1.find(text=re.compile(\"Seattle, WA Real Estate & Homes for Sale\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:42.889341Z",
     "start_time": "2018-10-07T23:54:42.853079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup1.find(text=re.compile(\"Seattle, WA Real Estate & Homes for Sale\")) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:45.244882Z",
     "start_time": "2018-10-07T23:54:45.007084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Built</th>\n",
       "      <th>Address</th>\n",
       "      <th>Unit Features</th>\n",
       "      <th>Number of Schools</th>\n",
       "      <th>Average School Rating</th>\n",
       "      <th>Median Rental Price</th>\n",
       "      <th>Median Listing Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4745 16th ave NE 4745 16th Ave NE, Seattle, WA...</td>\n",
       "      <td>[Dishwasher, Disposal]</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>684990.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type Built                                            Address  \\\n",
       "0  Apartment   NaN  4745 16th ave NE 4745 16th Ave NE, Seattle, WA...   \n",
       "\n",
       "            Unit Features  Number of Schools  Average School Rating  \\\n",
       "0  [Dishwasher, Disposal]                  5                    8.0   \n",
       "\n",
       "   Median Rental Price  Median Listing Price  \n",
       "0               2650.0              684990.0  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait_scrapper(soup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:48.408089Z",
     "start_time": "2018-10-07T23:54:48.404477Z"
    }
   },
   "outputs": [],
   "source": [
    "def meta_extract(soup, info):\n",
    "    meta = soup.find(id=\"ldp-property-meta\")\n",
    "    if meta:\n",
    "        l = meta.find(\"li\", attrs={\"data-label\": f\"property-meta-{info}\"})\n",
    "        if l:\n",
    "            return l.text.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:54:49.482566Z",
     "start_time": "2018-10-07T23:54:49.469166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"ldp-header-meta mobile-wrapper margin-bottom\" id=\"ldp-property-meta\">\n",
       "<ul class=\"property-meta list-horizontal list-style-disc list-spaced\" itemprop=\"description\">\n",
       "<li data-label=\"property-meta-beds\">\n",
       "<span class=\"data-value\">3</span>\n",
       "      beds\n",
       "    </li>\n",
       "<li data-label=\"property-meta-bath\">\n",
       "<span class=\"data-value\">2</span>\n",
       "      baths\n",
       "    </li>\n",
       "<li data-label=\"property-meta-sqft\">\n",
       "<span class=\"data-value\">1,200</span> sq ft\n",
       "    </li>\n",
       "</ul>\n",
       "</div>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = soup1.find(id=\"ldp-property-meta\")\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T05:25:04.341441Z",
     "start_time": "2018-10-08T05:25:04.332704Z"
    }
   },
   "outputs": [],
   "source": [
    "def single_page_scraper(soup):\n",
    "    df_trait = trait_scrapper(soup)\n",
    "\n",
    "    # Add floorplan to properties which have a table of floorplans,\n",
    "    # othrewise extract meta property information\n",
    "    if floorplan_scrapper1(soup) is not None:\n",
    "        df_floorplan = floorplan_scrapper1(soup)\n",
    "        # Avoid expanding the DataFrame for multiple times by accident\n",
    "        if(df_trait.shape[0] != df_floorplan.shape[0]):\n",
    "            df_trait = pd.concat([df_trait] * df_floorplan.shape[0], \n",
    "                           ignore_index=True)  \n",
    "        # Right append the trait columns to the floorplan DataFram\n",
    "        df1 = pd.concat([df_trait,df_floorplan], axis=1)\n",
    "\n",
    "    else:\n",
    "        df1 = df_trait\n",
    "        beds = meta_extract(soup, \"beds\")\n",
    "        bath = meta_extract(soup, \"bath\")\n",
    "        sqft = meta_extract(soup, \"sqft\")\n",
    "        pets = meta_extract(soup, \"pets\")\n",
    "        price = soup.find(itemprop=\"price\").text\n",
    "        if beds:\n",
    "            df1[\"Room Type\"] = beds[0] + \"-bedroom\" \n",
    "        if bath:\n",
    "            if len(bath) <= 2:\n",
    "                df1[\"Bath\"] = float(bath[0])\n",
    "            else:\n",
    "                df1[\"Bath\"] = float(bath[0]) + float(bath[2])*0.5 \n",
    "        if sqft:        \n",
    "            df1[\"Sqft\"] = float(sqft[0].replace(',',''))\n",
    "        if pets:\n",
    "            df1[\"Unit Features\"] = ' '.join(pets)\n",
    "        if len(price) != 0:\n",
    "            df1[\"Price\"] = float(price.\n",
    "                                 strip().\n",
    "                                 replace('$','').\n",
    "                                 replace(',',''))\n",
    "\n",
    "    # Reorder columns and fill missing values as Nan objects\n",
    "    cols = [\"Name\",\"Type\",\"Address\",\"Built\",\n",
    "                     \"Room Type\",\"Bath\",\"Sqft\",\"Price\",\n",
    "                    \"Number of Schools\",\"Average School Rating\",\n",
    "                    \"Median Rental Price\", \"Median Listing Price\",\n",
    "                    \"Community Features\",\"Unit Features\"]     \n",
    "    df2 = pd.DataFrame(columns = cols)\n",
    "    df = pd.concat([df2,df1], ignore_index = True)\n",
    "    df = df[cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:56:26.922894Z",
     "start_time": "2018-10-07T23:56:26.870701Z"
    }
   },
   "outputs": [],
   "source": [
    "soup1.find(itemprop = \"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:55:08.596887Z",
     "start_time": "2018-10-07T23:55:08.306656Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuriguang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:46: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Address</th>\n",
       "      <th>Built</th>\n",
       "      <th>Room Type</th>\n",
       "      <th>Bath</th>\n",
       "      <th>Sqft</th>\n",
       "      <th>Price</th>\n",
       "      <th>Number of Schools</th>\n",
       "      <th>Average School Rating</th>\n",
       "      <th>Median Rental Price</th>\n",
       "      <th>Median Listing Price</th>\n",
       "      <th>Community Features</th>\n",
       "      <th>Unit Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>4745 16th ave NE 4745 16th Ave NE, Seattle, WA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-bedroom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>684990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Dishwasher, Disposal]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name       Type                                            Address Built  \\\n",
       "0  NaN  Apartment  4745 16th ave NE 4745 16th Ave NE, Seattle, WA...   NaN   \n",
       "\n",
       "   Room Type  Bath    Sqft   Price Number of Schools  Average School Rating  \\\n",
       "0  3-bedroom   2.0  1200.0  2495.0                 5                    8.0   \n",
       "\n",
       "   Median Rental Price  Median Listing Price Community Features  \\\n",
       "0               2650.0              684990.0                NaN   \n",
       "\n",
       "            Unit Features  \n",
       "0  [Dishwasher, Disposal]  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test purposes\n",
    "df1 = single_page_scraper(soup1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T21:43:22.443702Z",
     "start_time": "2018-10-07T21:43:22.438327Z"
    }
   },
   "outputs": [],
   "source": [
    "def url_scrapper(total_page):\n",
    "    driver.get(\"https://www.realtor.com/apartments/Seattle_WA\")\n",
    "    \n",
    "    # Scrap 22 pages of urls of apartment for leasing into a list\n",
    "    j = 0 \n",
    "    urls = []\n",
    "    while j < total_page:\n",
    "        next_button = driver.find_element_by_class_name(\"next \")\n",
    "        next_button.click()\n",
    "        time.sleep(5) # Let's give the computer 5 seconds rest \n",
    "                      # after scraping a whole page of urls\n",
    "        soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "        for link in soup.find_all(class_=\"photo-wrap\"): \n",
    "            urls.append(\"https://www.realtor.com\"+link.find(\"a\")[\"href\"])\n",
    "        j += 1\n",
    "\n",
    "    # Save the url list in a csv file\n",
    "    url_file = open(\"data/urls.csv\", 'w')\n",
    "    for url in urls:\n",
    "        url_file.write(url + '\\n')\n",
    "    url_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T22:37:02.718837Z",
     "start_time": "2018-10-07T22:34:40.502174Z"
    }
   },
   "outputs": [],
   "source": [
    "url_scrapper(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T22:37:43.292385Z",
     "start_time": "2018-10-07T22:37:43.282383Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/urls.csv\", 'r') as f:\n",
    "    urls = f.read().split('\\n')\n",
    "    urls.remove('') # Remove empty strings\n",
    "    f.close()\n",
    "\n",
    "with open(\"data/urls.pkl\",'wb') as picklefile:\n",
    "    pickle.dump(urls, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:31:57.680496Z",
     "start_time": "2018-10-07T23:31:57.676153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:32:13.056999Z",
     "start_time": "2018-10-07T23:32:13.053447Z"
    }
   },
   "outputs": [],
   "source": [
    "urls = list(set(urls)) # Keep unique urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T23:32:15.329578Z",
     "start_time": "2018-10-07T23:32:15.324453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1167"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T22:38:00.224682Z",
     "start_time": "2018-10-07T22:38:00.218998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "for url in urls:\n",
    "    if url.startswith(\"https://www.realtor.com/realestateandhomes-detail/\"):\n",
    "        temp.append(url)\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T22:28:35.847906Z",
     "start_time": "2018-10-07T22:28:35.843245Z"
    }
   },
   "outputs": [],
   "source": [
    "def pickle_files(name):\n",
    "    if name.split('.')[1] == \"csv\":\n",
    "        data = pd.read_csv(name)\n",
    "    else: \n",
    "        f = open(name, 'r')\n",
    "        data = f.read().split('\\n')\n",
    "\n",
    "    pkl = name.split('.')[0] + \".pkl\"\n",
    "    with open(pkl,'wb') as picklefile:\n",
    "        pickle.dump(data, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T22:28:38.734416Z",
     "start_time": "2018-10-07T22:28:38.729611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.realtor.com/realestateandhomes-detail/2324-W-Newton-St-Apt-302_Seattle_WA_98199_M21149-70194',\n",
       " 'https://www.realtor.com/realestateandhomes-detail/3418A-22nd-Ave-W_Seattle_WA_98199_M29660-20775',\n",
       " 'https://www.realtor.com/realestateandhomes-detail/835-S-142nd-St_Burien_WA_98168_M24971-16354',\n",
       " 'https://www.realtor.com/realestateandhomes-detail/4308-Winslow-Pl-N-B_Seattle_WA_98103_M29900-95950',\n",
       " 'https://www.realtor.com/realestateandhomes-detail/8004-25th-Ave-NW_Seattle_WA_98117_M22901-40086']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T22:28:41.665139Z",
     "start_time": "2018-10-07T22:28:41.661310Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = [\"Name\",\"Type\",\"Address\",\"Built\",\n",
    "           \"Room Type\",\"Bath\",\"Sqft\",\"Price\",\n",
    "           \"Number of Schools\",\"Average School Rating\",\n",
    "           \"Median Rental Price\", \"Median Listing Price\",\n",
    "           \"Community Features\",\"Unit Features\",\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:57:34.665022Z",
     "start_time": "2018-10-08T06:55:33.816478Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuriguang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:46: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-9c3f6d5dfb77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"html5lib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf_property\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_page_scraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf_property\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_property\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-214-de1ab934c4b2>\u001b[0m in \u001b[0;36msingle_page_scraper\u001b[0;34m(soup)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_trait\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdf_floorplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             df_trait = pd.concat([df_trait] * df_floorplan.shape[0], \n\u001b[0;32m---> 11\u001b[0;31m                            ignore_index=True)  \n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Right append the trait columns to the floorplan DataFram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_trait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_floorplan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No objects to concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = cols)\n",
    "i = 0\n",
    "for url in urls[526:600]:\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source,\"html5lib\")\n",
    "    df_property = single_page_scraper(soup)\n",
    "    df_property[\"url\"] = url\n",
    "    df = pd.concat([df, df_property], ignore_index=True)\n",
    "    df.to_csv(\"data/rental_data13.csv\")\n",
    "    time.sleep(1)\n",
    "    i += 1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:58:25.450685Z",
     "start_time": "2018-10-08T06:58:25.439941Z"
    }
   },
   "outputs": [],
   "source": [
    "def multiple_page_scraper(url_source, data_destination, total_url): \n",
    "    \n",
    "    cols = [\"Name\",\"Type\",\"Address\",\"Built\",\n",
    "           \"Room Type\",\"Bath\",\"Sqft\",\"Price\",\n",
    "           \"Number of Schools\",\"Average School Rating\",\n",
    "           \"Median Rental Price\", \"Median Listing Price\",\n",
    "           \"Community Features\",\"Unit Features\",\"url\"]\n",
    "    df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    with open(url_source, 'r') as f:\n",
    "        urls = f.read().split('\\n')\n",
    "        f.close()\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    for url in urls[:total_url]:\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source,\"html5lib\")\n",
    "        df_property = single_page_scraper(soup)\n",
    "        df_property[\"url\"] = url\n",
    "        df = pd.concat([df, df_property], ignore_index=True)\n",
    "        df.to_csv(data_destination)\n",
    "        time.sleep(1)\n",
    "        i += 1\n",
    "        print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T21:44:11.464010Z",
     "start_time": "2018-10-07T21:43:11.383Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_files(\"data/rental_data.csv\")\n",
    "\n",
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
