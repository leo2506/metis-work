{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use newsapi to collect all pieces of news about trade war and store them in jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T06:19:21.178741Z",
     "start_time": "2018-11-11T06:19:20.264785Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('max_colwidth',10000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:22:21.488570Z",
     "start_time": "2018-11-08T21:22:21.484147Z"
    }
   },
   "outputs": [],
   "source": [
    "# A function specifies search conditions and generates an API url\n",
    "def generate_url(page,start,end):\n",
    "    url = ('https://newsapi.org/v2/everything?'\n",
    "       'q=\"trade war\"&'\n",
    "       'sources=[\"the-new-york-times\",\"cnn\",\"xinhua-net\"]&'\n",
    "       f'from={start}&'\n",
    "       f'to={end}&'\n",
    "       'sortBy=relevancy&'\n",
    "       'pageSize=100&'\n",
    "       f'page={page}&'\n",
    "       'apiKey=fc8921bcf53e482ba461714a254c0d7c'\n",
    "       )\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:27:18.489383Z",
     "start_time": "2018-11-08T21:27:18.483178Z"
    }
   },
   "outputs": [],
   "source": [
    "# A function takes in start and end dates of a time period,\n",
    "# and first searchs for articles within that period \n",
    "# based on the condition specified in the API url,\n",
    "# then writes the first 1000 articles of the searching result\n",
    "# into a csv file.\n",
    "def write_result(start,end):\n",
    "    \n",
    "    # Collect information about each article returned by the search\n",
    "    # Store the information in a list of jsons\n",
    "    result = []\n",
    "    for i in range(1,11):\n",
    "        response = requests.get(generate_url(i,start,end))\n",
    "        result.extend(response.json()['articles'])       \n",
    "\n",
    "    # Transport critical information of the article to a list of dictionaries\n",
    "    col = ['title','description','content','url','publishedAt']\n",
    "    df_dict = []\n",
    "    for article in result:\n",
    "        temp = {}\n",
    "        for c in col:\n",
    "            try: \n",
    "                temp[c] = article[c]\n",
    "            except:\n",
    "                temp[c] = np.nan\n",
    "        temp['source'] = article['source']['name']\n",
    "        df_dict.append(temp)\n",
    "    \n",
    "    # Convert the list of dicts into a pandas DataFrame\n",
    "    df = pd.DataFrame(df_dict,columns=col.append('source'))\n",
    "    \n",
    "    # Write the DataFrame into a csv file\n",
    "    st = ''.join(start.split('-')[1:])\n",
    "    en = ''.join(end.split('-')[1:])\n",
    "    df.to_csv(f'data/article_info({st}-{en}).csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:33:48.337592Z",
     "start_time": "2018-11-08T21:32:43.964593Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = write_result('2018-11-04','2018-11-08')\n",
    "df2 = write_result('2018-10-30','2018-11-03')\n",
    "df3 = write_result('2018-10-25','2018-10-29')\n",
    "df4 = write_result('2018-10-20','2018-10-24')\n",
    "df5 = write_result('2018-10-15','2018-10-19')\n",
    "df6 = write_result('2018-10-10','2018-10-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:47:54.289114Z",
     "start_time": "2018-11-08T21:47:54.277693Z"
    }
   },
   "outputs": [],
   "source": [
    "df_list = [df1,df2,df3,df4,df5,df6]\n",
    "df=pd.concat(df_list,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:48:02.104326Z",
     "start_time": "2018-11-08T21:48:02.100012Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:50:10.129934Z",
     "start_time": "2018-11-08T21:50:10.118801Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:52:40.427933Z",
     "start_time": "2018-11-08T21:52:40.419040Z"
    }
   },
   "outputs": [],
   "source": [
    "df.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:41:00.652551Z",
     "start_time": "2018-11-09T00:41:00.611291Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:53:40.416569Z",
     "start_time": "2018-11-08T21:53:40.309016Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/article_info_6000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T20:40:51.150041Z",
     "start_time": "2018-11-11T20:40:51.145638Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_stuff(doc,cv,ngram,max_df,min_df):\n",
    "    cv.ngram_range=(1,ngram)\n",
    "    cv.max_df = max_df\n",
    "    cv.min_df = min_df\n",
    "    x = cv.fit_transform(doc).toarray()\n",
    "    x = pd.DataFrame(x, columns=cv.get_feature_names())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T20:40:52.132605Z",
     "start_time": "2018-11-11T20:40:51.152129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5916, 26902)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf = fit_stuff(content,TfidfVectorizer(),2,0.2,2)\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T20:40:52.847978Z",
     "start_time": "2018-11-11T20:40:52.134819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5916, 26902)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv = fit_stuff(content,CountVectorizer(),2,0.2,2)\n",
    "X_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T20:40:52.852984Z",
     "start_time": "2018-11-11T20:40:52.850041Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T20:40:54.277343Z",
     "start_time": "2018-11-11T20:40:52.855077Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_cv, X_test_cv = train_test_split(X_cv, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T20:40:56.146414Z",
     "start_time": "2018-11-11T20:40:54.279760Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf = train_test_split(X_tfidf, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T20:40:56.152589Z",
     "start_time": "2018-11-11T20:40:56.148124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4141, 26902) (1775, 26902)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf.shape,X_test_tfidf.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
